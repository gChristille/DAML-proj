{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f876f550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from _04_mnist_digits.graph_dataset import GraphDataset # Needed for loading pickled dataset\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47d425bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to convert the images to tensors\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# Download and load the MNIST dataset\n",
    "train_dataset = datasets.MNIST(root='/data', train=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='/data', train=False, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e01ae511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([10000, 28, 28])\n",
      "torch.Size([60000])\n",
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "images_train = train_dataset.data\n",
    "labels_train = train_dataset.targets\n",
    "images_test = test_dataset.data \n",
    "labels_test = test_dataset.targets\n",
    "\n",
    "print(images_train.shape)\n",
    "print(images_test.shape)\n",
    "print(labels_train.shape)\n",
    "print(labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12b3d725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([70000, 28, 28])\n",
      "torch.Size([70000])\n"
     ]
    }
   ],
   "source": [
    "images = torch.cat((images_train, images_test), dim=0)\n",
    "labels = torch.cat((labels_train, labels_test), dim=0)\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5fec33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_centroid(segmented_image):\n",
    "    \"\"\"Find the centroid of each segment in the segmented image.\"\"\"\n",
    "    labels = np.unique(segmented_image)\n",
    "    centroids = {}\n",
    "    for label in labels:\n",
    "        coords = np.column_stack(np.where(segmented_image == label))\n",
    "        centroids[label] = coords.mean(axis=0)\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4fc4866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shared.img_to_graph import img_to_graph\n",
    "import skimage.segmentation as segm\n",
    "import skimage.graph as g\n",
    "import numpy as np\n",
    "\n",
    "img = images[0]\n",
    "\n",
    "if type(img) is not torch.Tensor:\n",
    "    img = torch.tensor(img)\n",
    "\n",
    "if img.ndim == 2:\n",
    "    img = img.unsqueeze(-1).repeat((1,1,3))\n",
    "elif img.ndim == 3 and img.shape[2] == 1:\n",
    "    img = img.repeat(1, 1, 3)\n",
    "\n",
    "quickshift_params = {\"kernel_size\": 3, \"max_dist\": 4, \"ratio\": 0.4}\n",
    "rag_params = {\"mode\": \"similarity\"}\n",
    "\n",
    "segmented_image = segm.quickshift(img.numpy(), **quickshift_params)\n",
    "graph: g.RAG = g.rag_mean_color(img.numpy(), segmented_image, **rag_params)\n",
    "\n",
    "edge_index = torch.tensor(list(graph.edges)).t().contiguous() # (2, num_edges)\n",
    "X = torch.zeros(len(graph.nodes)) # (mean color of each node)\n",
    "centroids = torch.zeros((len(graph.nodes), 2)) # (x,y coordinates)\n",
    "\n",
    "centroids_dict = find_centroid(segmented_image)\n",
    "\n",
    "for node_idx, node in enumerate(graph.nodes):\n",
    "    node_attr = graph.nodes[node][\"mean color\"]\n",
    "    X[node_idx] = torch.mean(torch.tensor(node_attr))\n",
    "    centroids[node_idx, :] = torch.tensor(centroids_dict[node])\n",
    "\n",
    "edge_weights = torch.zeros(edge_index.shape[1])  # (num_edges,)\n",
    "edges = list(graph.edges)\n",
    "for i in range(len(edges)):\n",
    "    n1, n2 = edges[i]\n",
    "    edge_weights[i] = torch.sqrt(\n",
    "        torch.sum((centroids[n1] - centroids[n2]) ** 2))\n",
    "\n",
    "# Normalizations\n",
    "edge_weights = edge_weights / (torch.sqrt(torch.tensor(2.))*img.shape[0])  # Normalize weights to [0, 1]\n",
    "X = X / 255  # Normalize colors to [0, 1]\n",
    "edge_weights = -torch.log(edge_weights)\n",
    "edge_weights /= edge_weights.max()  # Normalize edge weights to [0, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9160b728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': [np.int64(20)],\n",
      " 'mean color': array([1.11695906, 1.11695906, 1.11695906]),\n",
      " 'pixel count': 342,\n",
      " 'total color': array([382., 382., 382.])}\n",
      "{'labels': [np.int64(18)],\n",
      " 'mean color': array([0.5443787, 0.5443787, 0.5443787]),\n",
      " 'pixel count': 169,\n",
      " 'total color': array([92., 92., 92.])}\n",
      "{'labels': [np.int64(0)],\n",
      " 'mean color': array([131., 131., 131.]),\n",
      " 'pixel count': 2,\n",
      " 'total color': array([262., 262., 262.])}\n",
      "{'labels': [np.int64(3)],\n",
      " 'mean color': array([171., 171., 171.]),\n",
      " 'pixel count': 3,\n",
      " 'total color': array([513., 513., 513.])}\n",
      "{'labels': [np.int64(7)],\n",
      " 'mean color': array([249.60606061, 249.60606061, 249.60606061]),\n",
      " 'pixel count': 33,\n",
      " 'total color': array([8237., 8237., 8237.])}\n",
      "{'labels': [np.int64(1)],\n",
      " 'mean color': array([127., 127., 127.]),\n",
      " 'pixel count': 1,\n",
      " 'total color': array([127., 127., 127.])}\n",
      "{'labels': [np.int64(9)],\n",
      " 'mean color': array([100.5, 100.5, 100.5]),\n",
      " 'pixel count': 2,\n",
      " 'total color': array([201., 201., 201.])}\n",
      "{'labels': [np.int64(2)],\n",
      " 'mean color': array([162., 162., 162.]),\n",
      " 'pixel count': 2,\n",
      " 'total color': array([324., 324., 324.])}\n",
      "{'labels': [np.int64(4)],\n",
      " 'mean color': array([195., 195., 195.]),\n",
      " 'pixel count': 1,\n",
      " 'total color': array([195., 195., 195.])}\n",
      "{'labels': [np.int64(6)],\n",
      " 'mean color': array([53., 53., 53.]),\n",
      " 'pixel count': 3,\n",
      " 'total color': array([159., 159., 159.])}\n",
      "{'labels': [np.int64(5)],\n",
      " 'mean color': array([85.66666667, 85.66666667, 85.66666667]),\n",
      " 'pixel count': 3,\n",
      " 'total color': array([257., 257., 257.])}\n",
      "{'labels': [np.int64(10)],\n",
      " 'mean color': array([193., 193., 193.]),\n",
      " 'pixel count': 5,\n",
      " 'total color': array([965., 965., 965.])}\n",
      "{'labels': [np.int64(8)],\n",
      " 'mean color': array([80., 80., 80.]),\n",
      " 'pixel count': 1,\n",
      " 'total color': array([80., 80., 80.])}\n",
      "{'labels': [np.int64(13)],\n",
      " 'mean color': array([149.66666667, 149.66666667, 149.66666667]),\n",
      " 'pixel count': 3,\n",
      " 'total color': array([449., 449., 449.])}\n",
      "{'labels': [np.int64(11)],\n",
      " 'mean color': array([43., 43., 43.]),\n",
      " 'pixel count': 1,\n",
      " 'total color': array([43., 43., 43.])}\n",
      "{'labels': [np.int64(12)],\n",
      " 'mean color': array([154., 154., 154.]),\n",
      " 'pixel count': 1,\n",
      " 'total color': array([154., 154., 154.])}\n",
      "{'labels': [np.int64(14)],\n",
      " 'mean color': array([90., 90., 90.]),\n",
      " 'pixel count': 1,\n",
      " 'total color': array([90., 90., 90.])}\n",
      "{'labels': [np.int64(19)],\n",
      " 'mean color': array([75.5, 75.5, 75.5]),\n",
      " 'pixel count': 2,\n",
      " 'total color': array([151., 151., 151.])}\n",
      "{'labels': [np.int64(15)],\n",
      " 'mean color': array([40., 40., 40.]),\n",
      " 'pixel count': 2,\n",
      " 'total color': array([80., 80., 80.])}\n",
      "{'labels': [np.int64(23)],\n",
      " 'mean color': array([249.75, 249.75, 249.75]),\n",
      " 'pixel count': 40,\n",
      " 'total color': array([9990., 9990., 9990.])}\n",
      "{'labels': [np.int64(16)],\n",
      " 'mean color': array([155., 155., 155.]),\n",
      " 'pixel count': 2,\n",
      " 'total color': array([310., 310., 310.])}\n",
      "{'labels': [np.int64(17)],\n",
      " 'mean color': array([106.66666667, 106.66666667, 106.66666667]),\n",
      " 'pixel count': 3,\n",
      " 'total color': array([320., 320., 320.])}\n",
      "{'labels': [np.int64(25)],\n",
      " 'mean color': array([192.375, 192.375, 192.375]),\n",
      " 'pixel count': 8,\n",
      " 'total color': array([1539., 1539., 1539.])}\n",
      "{'labels': [np.int64(21)],\n",
      " 'mean color': array([64., 64., 64.]),\n",
      " 'pixel count': 1,\n",
      " 'total color': array([64., 64., 64.])}\n",
      "{'labels': [np.int64(22)],\n",
      " 'mean color': array([139., 139., 139.]),\n",
      " 'pixel count': 2,\n",
      " 'total color': array([278., 278., 278.])}\n",
      "{'labels': [np.int64(30)],\n",
      " 'mean color': array([0.2962963, 0.2962963, 0.2962963]),\n",
      " 'pixel count': 135,\n",
      " 'total color': array([40., 40., 40.])}\n",
      "{'labels': [np.int64(24)],\n",
      " 'mean color': array([114., 114., 114.]),\n",
      " 'pixel count': 1,\n",
      " 'total color': array([114., 114., 114.])}\n",
      "{'labels': [np.int64(27)],\n",
      " 'mean color': array([79.66666667, 79.66666667, 79.66666667]),\n",
      " 'pixel count': 3,\n",
      " 'total color': array([239., 239., 239.])}\n",
      "{'labels': [np.int64(26)],\n",
      " 'mean color': array([66., 66., 66.]),\n",
      " 'pixel count': 1,\n",
      " 'total color': array([66., 66., 66.])}\n",
      "{'labels': [np.int64(29)],\n",
      " 'mean color': array([217.5, 217.5, 217.5]),\n",
      " 'pixel count': 4,\n",
      " 'total color': array([870., 870., 870.])}\n",
      "{'labels': [np.int64(28)],\n",
      " 'mean color': array([171.5, 171.5, 171.5]),\n",
      " 'pixel count': 2,\n",
      " 'total color': array([343., 343., 343.])}\n",
      "{'labels': [np.int64(31)],\n",
      " 'mean color': array([55., 55., 55.]),\n",
      " 'pixel count': 1,\n",
      " 'total color': array([55., 55., 55.])}\n",
      "{'labels': [np.int64(33)],\n",
      " 'mean color': array([133.33333333, 133.33333333, 133.33333333]),\n",
      " 'pixel count': 3,\n",
      " 'total color': array([400., 400., 400.])}\n",
      "{'labels': [np.int64(32)],\n",
      " 'mean color': array([136., 136., 136.]),\n",
      " 'pixel count': 1,\n",
      " 'total color': array([136., 136., 136.])}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "for node in graph.nodes:\n",
    "    pprint(graph.nodes[node])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6d0cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daml-proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
